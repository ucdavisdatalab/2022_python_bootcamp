# Workshop: Python Intensive Training


_[UC Davis DataLab](https://datalab.ucdavis.edu/)_  
_Fall 2022_  
_Instructor: Maggie Berrens <<mlberrens@ucdavis.edu>>, Parker Bremer <<plbremer@ucdavis.edu>>, Frank Cerasoli <<ftcerasoli@ucdavis.edu>>_  

* [Reader](https://ucdavisdatalab.github.io/python_intensive_training/)
* [Event Page](https://datalab.ucdavis.edu/eventscalendar/YOUR_EVENT/)

This three-day course is designed to prepare incoming (or experienced) graduate students and post docs with little to no coding experience for the coding demands that many graduate courses and research often requires. In the past this training was fully run by graduate students held over zoom or in a random classroom. This year we have teamed up with the UC Davis Data lab, who have offered their assistance in running the workshop and providing space for the workshop to take place. With that being said this intensive training is still majorly put together and run by graduate students and post docs aimed to help other graduate students and post docs. The intensive training will take place over September 6th - 8th from 5 pm - 7 pm with limited seating on campus in the Shields 360 (DataLab classroom) as well as on Zoom for those who don't obtain a spot for in person. This is a great opportunity to learn a new skill and meet other graduate students! Each session will begin with about an hour of demonstration to teach fundamental Python topics. This will be followed by time where studetns can work on an assignment with each other and ask questions to volunteers. The assignment each day will build off the previous sessions so by the end you will have a complete Python project!

## Goals

After this workshop, learners will be familiar with:

* Basic Python programming syntax
* Commonly used libraries such as NumPy and Pandas 
* Visualization tools, writing reusable functions
* Identifying where to go to learn more.

## Prerequisites

No prior programming experience is necessary.


## Contributing

The course reader is a live webpage, hosted through GitHub, where you can enter
curriculum content and post it to a public-facing site for learners.

To make alterations to the reader:

1.  Run `git pull`, or if it's your first time contributing, see the
    [Setup](#setup) section of this document.

2.  Edit an existing chapter file or create a new one. Chapter files are
    Markdown files (`.md`) in the `chapters/` directory. Enter your text, code,
    and other information directly into the file. Make sure your file:

    - Follows the naming scheme `##_topic-of-chapter.md` (the only exception is
      `index.md`, which contains the reader's front page).
    - Begins with a first-level header (like `# This`). This will be the title
      of your chapter. Subsequent section headers should be second-level
      headers (like `## This`) or below.

    Put any supporting resources in `data/` or `img/`. For large files, see the
    [Large Files](#large-files) section of this document. You do not need to
    add resources generated by your code (such as plots). The next step saves
    these in `docs/` automatically.

3.  Run the command `jupyter-book build .` in a shell at the top level of the
    repo to regenerate the HTML files in the `_build/`.

4.  When you're finished, `git add`:
    - Any files you edited directly
    - Any supporting media you added to `img/`
    - The `.gitattributes` file (if you added a large file)

    Then `git commit` and `git push`. This updates the `main` branch of the
    repo, which contains source materials for the web page (but not the web
    page itself).

5.  Run the command `ghp-import -n -p -f _build/html` in a shell at the top
    level of the repo to update the `gh-pages` branch of the repo. This uses
    the [`ghp-import` Python package][ghp-import], which you will need to
    install first (`pip install ghp-import`). The live web page will update
    automatically after 1-10 minutes.

[ghp-import]: https://github.com/c-w/ghp-import

### Large Files

If you want to include a large file (say over 1 MB), you should use git LFS.
You can register a large file with git LFS with the shell command:

```sh
git lfs track YOUR_FILE
```

This command updates the `.gitattributes` file at the top level of the repo. To
make sure the change is saved, you also need to run:

```sh
git add .gitattributes
```

Now that your large is registered with git LFS, you can add, commit, and push
the file with git the same way you would any other file, and git LFS will
automatically intercede as needed.

GitHub provides 1 GB of storage and 1 GB of monthly bandwidth free per repo for
large files. If your large file is more than 50 MB, check with the other
contributors before adding it.

## Setup

### Python Packages

We recommend using or [mamba][] (or the slower but equivalent [conda][]) to
manage Python dependencies. You can create a new conda environment with all of
the packages necessary to build the book with this command:

```sh
mamba env create --name intro-py python jupyter-book ghp-import
```

[mamba]: https://mamba.readthedocs.io/
[conda]: https://docs.conda.io/en/latest/
